{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6927407 [0.09333334]\n",
      "0.0119848205 [0.87284565]\n",
      "0.0074058846 [0.9000496]\n",
      "0.004576392 [0.9214299]\n",
      "0.0028279328 [0.93823665]\n",
      "0.0017474812 [0.95144856]\n",
      "0.0010798369 [0.96183413]\n",
      "0.0006672758 [0.96999824]\n",
      "0.0004123322 [0.97641575]\n",
      "0.00025479682 [0.98146063]\n",
      "0.00015745126 [0.98542637]\n",
      "9.729493e-05 [0.9885437]\n",
      "6.0121714e-05 [0.99099445]\n",
      "3.7151633e-05 [0.9929208]\n",
      "2.295738e-05 [0.99443513]\n",
      "1.4186136e-05 [0.9956255]\n",
      "8.766266e-06 [0.99656117]\n",
      "5.417051e-06 [0.9972968]\n",
      "3.3472788e-06 [0.99787503]\n",
      "2.06872e-06 [0.9983296]\n",
      "1.2782984e-06 [0.99868685]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.zeros([1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run([cost, optimizer],feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 ==0:\n",
    "            print(sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3086.4714 [[0.8055684 ]\n",
      " [1.5540457 ]\n",
      " [0.29063857]] [0.01186101]\n",
      "1029.2933 [[0.6268557 ]\n",
      " [1.3782178 ]\n",
      " [0.09846403]] [0.01025253]\n",
      "1028.2184 [[0.62267375]\n",
      " [1.3804691 ]\n",
      " [0.09114929]] [0.01082818]\n",
      "1027.7578 [[0.62152976]\n",
      " [1.385701  ]\n",
      " [0.08702312]] [0.01144104]\n",
      "1027.3071 [[0.6204856 ]\n",
      " [1.3909155 ]\n",
      " [0.08297321]] [0.01205433]\n",
      "1026.8662 [[0.61948985]\n",
      " [1.3960617 ]\n",
      " [0.07894575]] [0.01266741]\n",
      "1026.4355 [[0.6185408 ]\n",
      " [1.4011401 ]\n",
      " [0.07493951]] [0.01328029]\n",
      "1026.0135 [[0.6176379 ]\n",
      " [1.4061517 ]\n",
      " [0.07095444]] [0.01389296]\n",
      "1025.6003 [[0.6167801]\n",
      " [1.4110972]\n",
      " [0.0669901]] [0.01450542]\n",
      "1025.1965 [[0.61596686]\n",
      " [1.4159781 ]\n",
      " [0.06304629]] [0.01511768]\n",
      "1024.801 [[0.61519724]\n",
      " [1.4207953 ]\n",
      " [0.05912267]] [0.01572974]\n",
      "1024.4132 [[0.6144707 ]\n",
      " [1.4255494 ]\n",
      " [0.05521897]] [0.0163416]\n",
      "1024.0339 [[0.61378646]\n",
      " [1.4302418 ]\n",
      " [0.05133508]] [0.01695327]\n",
      "1023.6623 [[0.6131436 ]\n",
      " [1.4348733 ]\n",
      " [0.04747057]] [0.01756474]\n",
      "1023.29803 [[0.6125417 ]\n",
      " [1.4394449 ]\n",
      " [0.04362533]] [0.01817602]\n",
      "1022.94104 [[0.61197996]\n",
      " [1.4439573 ]\n",
      " [0.03979915]] [0.01878711]\n",
      "1022.59094 [[0.61145765]\n",
      " [1.4484117 ]\n",
      " [0.03599176]] [0.01939801]\n",
      "1022.2484 [[0.61097425]\n",
      " [1.4528091 ]\n",
      " [0.03220289]] [0.02000872]\n",
      "1021.9119 [[0.6105287 ]\n",
      " [1.4571496 ]\n",
      " [0.02843235]] [0.02061925]\n",
      "1021.58185 [[0.61012083]\n",
      " [1.461435  ]\n",
      " [0.0246799 ]] [0.0212296]\n",
      "1021.2585 [[0.60974973]\n",
      " [1.4656658 ]\n",
      " [0.02094535]] [0.02183977]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[73., 69., 79.],\n",
    "          [65., 91., 76.],\n",
    "          [90., 89., 99.],\n",
    "          [73., 66., 70.],\n",
    "          [93., 88., 93.]]\n",
    "\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.000001).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 ==0:\n",
    "            print(sess.run(cost,feed_dict={X:x_data, Y:y_data}), sess.run(W), sess.run(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6378161 [[-0.61153454]\n",
      " [ 1.4943085 ]] [1.1830168]\n",
      "1.230729 [[-0.5568453]\n",
      " [ 0.9520428]] [0.9176297]\n",
      "0.9814674 [[-0.3195859 ]\n",
      " [ 0.56533647]] [0.71017987]\n",
      "0.80559874 [[-0.10760351]\n",
      " [ 0.2559573 ]] [0.52373844]\n",
      "0.69113755 [[0.06888194]\n",
      " [0.02037177]] [0.35818508]\n",
      "0.6183917 [[ 0.21171567]\n",
      " [-0.15377711]] [0.2106911]\n",
      "0.5709577 [[ 0.32650533]\n",
      " [-0.28149077]] [0.07727525]\n",
      "0.5384005 [[ 0.41926423]\n",
      " [-0.37527698]] [-0.04551827]\n",
      "0.5146943 [[ 0.49502674]\n",
      " [-0.44426033]] [-0.16025501]\n",
      "0.4964166 [[ 0.55766034]\n",
      " [-0.49484643]] [-0.26875332]\n",
      "0.48158923 [[ 0.6100614 ]\n",
      " [-0.53153574]] [-0.37229872]\n",
      "0.4690362 [[ 0.65439653]\n",
      " [-0.55754244]] [-0.47181228]\n",
      "0.45803645 [[ 0.6923023 ]\n",
      " [-0.57521176]] [-0.5679678]\n",
      "0.44813502 [[ 0.7250289 ]\n",
      " [-0.58629096]] [-0.6612667]\n",
      "0.43903723 [[ 0.75354564]\n",
      " [-0.59210825]] [-0.7520908]\n",
      "0.43054745 [[ 0.778613 ]\n",
      " [-0.5936914]] [-0.8407353]\n",
      "0.42253336 [[ 0.800835  ]\n",
      " [-0.59184766]] [-0.9274319]\n",
      "0.41490367 [[ 0.82069635]\n",
      " [-0.58722   ]] [-1.0123647]\n",
      "0.40759385 [[ 0.8385896]\n",
      " [-0.580326 ]] [-1.0956832]\n",
      "0.40055823 [[ 0.85483515]\n",
      " [-0.5715867 ]] [-1.1775086]\n",
      "0.39376315 [[ 0.8696969 ]\n",
      " [-0.56134695]] [-1.2579416]\n",
      "0.38718393 [[ 0.8833921]\n",
      " [-0.5498919]] [-1.3370659]\n",
      "0.3808016 [[ 0.89610255]\n",
      " [-0.53745735]] [-1.4149535]\n",
      "0.37460193 [[ 0.90797955]\n",
      " [-0.52424014]] [-1.4916617]\n",
      "0.3685733 [[ 0.9191499 ]\n",
      " [-0.51040566]] [-1.5672442]\n",
      "0.36270645 [[ 0.9297203 ]\n",
      " [-0.49609184]] [-1.6417453]\n",
      "0.3569938 [[ 0.9397804 ]\n",
      " [-0.48141462]] [-1.7152048]\n",
      "0.35142887 [[ 0.9494065]\n",
      " [-0.4664722]] [-1.7876573]\n",
      "0.34600568 [[ 0.95866245]\n",
      " [-0.4513468 ]] [-1.8591343]\n",
      "0.34071946 [[ 0.9676027]\n",
      " [-0.4361076]] [-1.9296631]\n",
      "0.33556557 [[ 0.97627336]\n",
      " [-0.4208132 ]] [-1.9992696]\n",
      "0.33053967 [[ 0.98471314]\n",
      " [-0.40551227]] [-2.0679774]\n",
      "0.325638 [[ 0.9929555]\n",
      " [-0.3902461]] [-2.135808]\n",
      "0.32085666 [[ 1.0010283 ]\n",
      " [-0.37504902]] [-2.2027812]\n",
      "0.31619227 [[ 1.0089552 ]\n",
      " [-0.35994944]] [-2.268916]\n",
      "0.3116413 [[ 1.0167564]\n",
      " [-0.344971 ]] [-2.3342302]\n",
      "0.30720046 [[ 1.0244488]\n",
      " [-0.330133 ]] [-2.3987422]\n",
      "0.30286673 [[ 1.0320469 ]\n",
      " [-0.31545153]] [-2.4624655]\n",
      "0.29863694 [[ 1.039563  ]\n",
      " [-0.30093938]] [-2.525417]\n",
      "0.2945082 [[ 1.0470067 ]\n",
      " [-0.28660652]] [-2.5876112]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "logits = tf.matmul(X, W)+b\n",
    "hypothesis = tf.sigmoid(logits)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "prediction = tf.cast(hypothesis > 5, dtype=tf.float32) # dtype\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(4000):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 ==0:\n",
    "            print(sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W),sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt(\"C:/project/python_data/tensor/exam_181121.csv\", dtype=np.float32,\n",
    "               delimiter=','  ,skiprows=1)\n",
    "\n",
    "x_data = xy[:, : -1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([6, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 6])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, shape=[-1, nb_classes]) \n",
    "\n",
    "logits = tf.matmul(X, W) +b\n",
    "hypothesis = tf.nn.softmax(logits) # 전체값의 합이 1인 데이터로 만들어준다\n",
    "                                   # [0.7, 0,2, 0.1]\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y_one_hot*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 ==0:\n",
    "            print(sess.run(cost, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-10-1c305867afbc>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 1.443888507\n",
      "Epoch: 0002 cost = 0.518277024\n",
      "Epoch: 0003 cost = 0.427833479\n",
      "Epoch: 0004 cost = 0.377509895\n",
      "Epoch: 0005 cost = 0.352007292\n",
      "Epoch: 0006 cost = 0.332984598\n",
      "Epoch: 0007 cost = 0.318717588\n",
      "Epoch: 0008 cost = 0.308272844\n",
      "Epoch: 0009 cost = 0.302883573\n",
      "Epoch: 0010 cost = 0.297880258\n",
      "Epoch: 0011 cost = 0.290484417\n",
      "Epoch: 0012 cost = 0.284524700\n",
      "Epoch: 0013 cost = 0.284736746\n",
      "Epoch: 0014 cost = 0.281085054\n",
      "Epoch: 0015 cost = 0.277070173\n",
      "Epoch: 0016 cost = 0.276672494\n",
      "Epoch: 0017 cost = 0.276148665\n",
      "Epoch: 0018 cost = 0.270588422\n",
      "Epoch: 0019 cost = 0.272564013\n",
      "Epoch: 0020 cost = 0.270054031\n",
      "Epoch: 0021 cost = 0.267436061\n",
      "Epoch: 0022 cost = 0.268269590\n",
      "Epoch: 0023 cost = 0.265126156\n",
      "Epoch: 0024 cost = 0.268664923\n",
      "Epoch: 0025 cost = 0.264783086\n",
      "Epoch: 0026 cost = 0.264498553\n",
      "Epoch: 0027 cost = 0.262456352\n",
      "Epoch: 0028 cost = 0.261635315\n",
      "Epoch: 0029 cost = 0.261619018\n",
      "Epoch: 0030 cost = 0.260075193\n",
      "Learning Finished\n",
      "Accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784]) # 28 x 28\n",
    "Y = tf.placeholder(tf.float32, shape=[None, nb_classes]) # one_hot\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "logits = tf.matmul(X, W) +b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# cost = -tf.reduce_mean(tf.reduce_sum(Y*tf.log(hypothesis), axis= 1))\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "training_epochs= 30\n",
    "batch_size= 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost= 0\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost,optimizer], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print(\"Epoch:\",\"%04d\" % (epoch + 1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Learning Finished\")\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                                    Y: mnist.test.labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 001 cost = 178.635944118\n",
      "Epoch: 002 cost = 38.122501264\n",
      "Epoch: 003 cost = 23.764233700\n",
      "Epoch: 004 cost = 16.600981641\n",
      "Epoch: 005 cost = 12.085855333\n",
      "Epoch: 006 cost = 8.875396710\n",
      "Epoch: 007 cost = 6.691472478\n",
      "Epoch: 008 cost = 4.846880882\n",
      "Epoch: 009 cost = 3.629433943\n",
      "Epoch: 010 cost = 2.733767407\n",
      "Epoch: 011 cost = 2.003501886\n",
      "Epoch: 012 cost = 1.565291535\n",
      "Epoch: 013 cost = 1.099528643\n",
      "Epoch: 014 cost = 0.864463382\n",
      "Epoch: 015 cost = 0.666819852\n",
      "Epoch: 016 cost = 0.574784273\n",
      "Epoch: 017 cost = 0.554344570\n",
      "Epoch: 018 cost = 0.455467088\n",
      "Epoch: 019 cost = 0.402436282\n",
      "Epoch: 020 cost = 0.366224816\n",
      "Epoch: 021 cost = 0.369397425\n",
      "Epoch: 022 cost = 0.327182570\n",
      "Epoch: 023 cost = 0.296578305\n",
      "Epoch: 024 cost = 0.341962495\n",
      "Epoch: 025 cost = 0.294281931\n",
      "Epoch: 026 cost = 0.280270263\n",
      "Epoch: 027 cost = 0.349932445\n",
      "Epoch: 028 cost = 0.266537688\n",
      "Epoch: 029 cost = 0.223310355\n",
      "Epoch: 030 cost = 0.174508456\n",
      "Learning Finished\n",
      "Accuracy: 0.9598\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784]) # 28 x 28\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10]) # one_hot\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1)+ b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2)+ b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2, W3)+ b3\n",
    "\n",
    "# cost = -tf.reduce_mean(tf.reduce_sum(Y*tf.log(hypothesis), axis= 1))\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "training_epochs= 30\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print(\"Epoch:\",\"%03d\" % (epoch + 1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "    print(\"Learning Finished\")\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                                    Y: mnist.test.labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch : 001 cost = 0.415940833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3a1b604b005c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%03d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cost =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"{:.9f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784]) # 28 x 28\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10]) # one_hot\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1)+b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2)+ b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "logits = tf.matmul(L2, W3)+ b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                             labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys, keep_prob:0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"Epoch :\", \"%03d\" % (epoch + 1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels,\n",
    "                                                keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1)+ b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "logits = tf.matmul(layer1, W2)+ b2\n",
    "hypothesis = tf.sigmoid(logits)\n",
    "#hypothesis = tf.sigmoid(tf.matmul(layer1, W2) +b2)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+ (1-Y)*tf.log(1-hypothesis))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype= tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 ==0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run([W1,W2]))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print(\"\\nHypothesis:\", h, \"\\nCorrect:\",c, \"\\nAccuracy:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.5197012\n",
      "200 0.28977916\n",
      "300 0.18376529\n",
      "400 0.12068415\n",
      "500 0.082982965\n",
      "600 0.05983226\n",
      "700 0.04486699\n",
      "800 0.03484809\n",
      "900 0.027769415\n",
      "1000 0.022651052\n",
      "1100 0.01879393\n",
      "1200 0.015838316\n",
      "1300 0.013520677\n",
      "1400 0.011664215\n",
      "1500 0.010155342\n",
      "1600 0.0089115985\n",
      "1700 0.007878363\n",
      "1800 0.0070005744\n",
      "1900 0.006257421\n",
      "2000 0.0056188344\n",
      "2100 0.005068679\n",
      "2200 0.004588931\n",
      "2300 0.0041691246\n",
      "2400 0.0037992767\n",
      "2500 0.0034718753\n",
      "2600 0.003181667\n",
      "2700 0.0029219107\n",
      "2800 0.0026892324\n",
      "2900 0.0024805823\n",
      "3000 0.0022916177\n",
      "[[  5.5794363   -0.7506831  -10.216295  ]\n",
      " [ -1.3995256    4.9835544   -0.29171753]\n",
      " [-27.886204    26.746235    37.374214  ]\n",
      " [  5.5794363   -0.7506831  -10.216295  ]\n",
      " [  5.5794363   -0.7506831  -10.216295  ]\n",
      " [-20.905048    21.010195    27.446512  ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array(\n",
    "[[0,0], [1,0], [1,1], [0,0], [0,0], [0,1]])\n",
    "\n",
    "y_data = np.array([\n",
    "    [1,0,0], # one-hot [기타, 포유류, 조류]\n",
    "    [0,1,0],\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2,3], -1.0, 1.0))\n",
    "b1 = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "L1 = tf.matmul(X, W1) +b1\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([3,3], -1.0, 1.0))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "L2 = tf.matmul(L1, W2) +b2\n",
    "\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(Y *tf.log(model), axis=1))\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=L2, labels=Y)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(3000):\n",
    "    sess.run(train_op, feed_dict = {X: x_data, Y:y_data})\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict = {X:x_data, Y:y_data}))\n",
    "        \n",
    "print(sess.run(L2, feed_dict={X:x_data}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
